{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8166514,"sourceType":"datasetVersion","datasetId":4826829},{"sourceId":8262224,"sourceType":"datasetVersion","datasetId":4904105}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MS Lesion Segmentation UNET Inference","metadata":{}},{"cell_type":"markdown","source":"Perform inference for an ensemble of models:\n* save 3D Nifti images of predicted probability maps averaged across ensemble models (saved to \"*pred_prob.nii.gz\" files), \n* binary segmentation maps predicted obtained by thresholding of average predictions and removing all connected components smaller than 9 voxels (saved to \"pred_seg.nii.gz\"), \n* uncertainty maps for reversed mutual information measure (saved to \"uncs_rmi.nii.gz\").","metadata":{}},{"cell_type":"markdown","source":"## Install libraries ","metadata":{}},{"cell_type":"code","source":"!pip install monai==0.9.0","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:27:24.732888Z","iopub.execute_input":"2024-05-03T09:27:24.733358Z","iopub.status.idle":"2024-05-03T09:27:38.925125Z","shell.execute_reply.started":"2024-05-03T09:27:24.733317Z","shell.execute_reply":"2024-05-03T09:27:38.924009Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting monai==0.9.0\n  Downloading monai-0.9.0-202206131636-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from monai==0.9.0) (2.1.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from monai==0.9.0) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->monai==0.9.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->monai==0.9.0) (1.3.0)\nDownloading monai-0.9.0-202206131636-py3-none-any.whl (939 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: monai\nSuccessfully installed monai-0.9.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Libraries import","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport torch\nimport numpy as np\nfrom glob import glob\nfrom monai.inferers import sliding_window_inference\nfrom monai.networks.nets import SegResNet\nfrom monai.data import write_nifti\nfrom monai.data import CacheDataset, DataLoader\nfrom monai.transforms import (\n    AddChanneld, Compose, LoadImaged, RandCropByPosNegLabeld,\n    Spacingd, ToTensord, NormalizeIntensityd, RandFlipd,\n    RandRotate90d, RandShiftIntensityd, RandAffined, RandSpatialCropd,\n    RandScaleIntensityd)\nfrom scipy import ndimage\n#from data_load import remove_connected_components, get_flair_dataloader\n#from uncertainty import ensemble_uncertainties_classification","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:27:38.927083Z","iopub.execute_input":"2024-05-03T09:27:38.927396Z","iopub.status.idle":"2024-05-03T09:28:15.098037Z","shell.execute_reply.started":"2024-05-03T09:27:38.927365Z","shell.execute_reply":"2024-05-03T09:28:15.097057Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-03 09:28:06.876068: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-03 09:28:06.876217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-03 09:28:07.012935: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setup functions","metadata":{}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\" Set device \"\"\"\n    if torch.cuda.is_available():\n        print(\"Got CUDA!\")\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:28:15.099264Z","iopub.execute_input":"2024-05-03T09:28:15.100171Z","iopub.status.idle":"2024-05-03T09:28:15.105391Z","shell.execute_reply.started":"2024-05-03T09:28:15.100140Z","shell.execute_reply":"2024-05-03T09:28:15.104359Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Data load","metadata":{}},{"cell_type":"code","source":"def get_val_transforms(keys=[\"image\", \"label\"], image_keys=[\"image\"]):\n    \"\"\" Get transforms for testing on FLAIR images and ground truth:\n    - Loads 3D images and masks from Nifti file\n    - Adds channel dimention\n    - Applies intensity normalisation to scans\n    - Converts to torch.Tensor()\n    \"\"\"\n    return Compose(\n        [\n            LoadImaged(keys=keys),\n            AddChanneld(keys=keys),\n            NormalizeIntensityd(keys=image_keys, nonzero=True),\n            ToTensord(keys=keys),\n        ]\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:28:15.108243Z","iopub.execute_input":"2024-05-03T09:28:15.108723Z","iopub.status.idle":"2024-05-03T09:28:15.115885Z","shell.execute_reply.started":"2024-05-03T09:28:15.108691Z","shell.execute_reply":"2024-05-03T09:28:15.114958Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_flair_dataloader(flair_path, num_workers, cache_rate=0.1, bm_path=None):\n    \"\"\"\n    Get dataloader with FLAIR images only for inference\n    \n    Args:\n      flair_path: `str`, path to directory with FLAIR images from Train set.\n      num_workers:  `int`,  number of worker threads to use for parallel processing\n                    of images\n      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n      bm_path:   `None|str`. If `str`, then defines path to directory with\n                 brain masks. If `None`, dataloader does not return brain masks.\n    Returns:\n      monai.data.DataLoader() class object.\n    \"\"\"\n    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii\")),\n                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n\n    if bm_path is not None:\n        bms = sorted(glob(os.path.join(bm_path, \"*isovox_fg_mask.nii\")),\n                     key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding brain masks\n\n        assert len(flair) == len(bms), f\"Some files must be missing: {[len(flair), len(bms)]}\"\n\n        files = [{\"image\": fl, \"brain_mask\": bm} for fl, bm in zip(flair, bms)]\n\n        val_transforms = get_val_transforms(keys=[\"image\", \"brain_mask\"])\n    else:\n        files = [{\"image\": fl} for fl in flair]\n\n        val_transforms = get_val_transforms(keys=[\"image\"])\n\n    print(\"Number of FLAIR files:\", len(files))\n\n    ds = CacheDataset(data=files, transform=val_transforms,\n                      cache_rate=cache_rate, num_workers=num_workers)\n    return DataLoader(ds, batch_size=1, shuffle=False,\n                      num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:28:15.117089Z","iopub.execute_input":"2024-05-03T09:28:15.117417Z","iopub.status.idle":"2024-05-03T09:28:15.128127Z","shell.execute_reply.started":"2024-05-03T09:28:15.117387Z","shell.execute_reply":"2024-05-03T09:28:15.127254Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def remove_connected_components(segmentation, l_min=9):\n    \"\"\"\n    Remove all lesions with less or equal amount of voxels than `l_min` from a \n    binary segmentation mask `segmentation`.\n    Args:\n      segmentation: `numpy.ndarray` of shape [H, W, D], with a binary lesions segmentation mask.\n      l_min:  `int`, minimal amount of voxels in a lesion.\n    Returns:\n      Binary lesion segmentation mask (`numpy.ndarray` of shape [H, W, D])\n      only with connected components that have more than `l_min` voxels.\n    \"\"\"\n    labeled_seg, num_labels = ndimage.label(segmentation)\n    label_list = np.unique(labeled_seg)\n    num_elements_by_lesion = ndimage.labeled_comprehension(segmentation, labeled_seg, label_list, np.sum, float, 0)\n\n    seg2 = np.zeros_like(segmentation)\n    for i_el, n_el in enumerate(num_elements_by_lesion):\n        if n_el > l_min:\n            current_voxels = np.stack(np.where(labeled_seg == i_el), axis=1)\n            seg2[current_voxels[:, 0],\n                 current_voxels[:, 1],\n                 current_voxels[:, 2]] = 1\n    return seg2","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:28:15.129257Z","iopub.execute_input":"2024-05-03T09:28:15.129564Z","iopub.status.idle":"2024-05-03T09:28:15.144473Z","shell.execute_reply.started":"2024-05-03T09:28:15.129541Z","shell.execute_reply":"2024-05-03T09:28:15.143606Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Uncertainty","metadata":{}},{"cell_type":"code","source":"def renyi_entropy_of_expected(probs, alpha=0.8):\n    \"\"\"\n    Renyi entropy is a generalised version of Shannon - the two are equivalent for alpha=1\n    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n    \"\"\"\n    scale = 1. / (1. - alpha)\n    mean_probs = np.mean(probs, axis=0)\n    return scale * np.log( np.sum(mean_probs**alpha, axis=-1) )\n\ndef renyi_expected_entropy(probs, alpha=0.8):\n    \"\"\"\n    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n    \"\"\"\n    scale = 1. / (1. - alpha)\n    return np.mean( scale * np.log( np.sum(probs**alpha, axis=-1) ), axis=0)\n\n\ndef entropy_of_expected(probs, epsilon=1e-10):\n    \"\"\"\n    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n    \"\"\"\n    mean_probs = np.mean(probs, axis=0)\n    log_probs = -np.log(mean_probs + epsilon)\n    return np.sum(mean_probs * log_probs, axis=-1)\n\ndef expected_entropy(probs, epsilon=1e-10):\n    \"\"\"\n    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n    \"\"\"\n    log_probs = -np.log(probs + epsilon)\n    return np.mean(np.sum(probs * log_probs, axis=-1), axis=0)\n\n\ndef ensemble_uncertainties_classification(probs, epsilon=1e-10):\n    \"\"\"\n    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n    :return: Dictionary of uncertainties\n    \"\"\"\n    mean_probs = np.mean(probs, axis=0)\n    mean_lprobs = np.mean(np.log(probs + epsilon), axis=0)\n    conf = np.max(mean_probs, axis=-1)\n\n    eoe = entropy_of_expected(probs, epsilon)\n    exe = expected_entropy(probs, epsilon)\n\n    mutual_info = eoe - exe\n\n    epkl = -np.sum(mean_probs * mean_lprobs, axis=-1) - exe\n\n    uncertainty = {'confidence': -1 * conf,\n                   'entropy_of_expected': eoe,\n                   'expected_entropy': exe,\n                   'mutual_information': mutual_info,\n                   'epkl': epkl,\n                   'reverse_mutual_information': epkl - mutual_info,\n                   }\n\n    return uncertainty","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:28:15.146298Z","iopub.execute_input":"2024-05-03T09:28:15.146614Z","iopub.status.idle":"2024-05-03T09:28:15.162423Z","shell.execute_reply.started":"2024-05-03T09:28:15.146584Z","shell.execute_reply":"2024-05-03T09:28:15.161551Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Inference function","metadata":{}},{"cell_type":"code","source":"def inferenceUNET(path_pred, path_data, path_bm, threshold = 0.35, num_models = 3, path_model = '', num_workers = 1):\n    \n    #Setting up output directory\n    os.makedirs(path_pred, exist_ok=True)\n    \n    #Settin up device\n    device = get_default_device()\n    torch.multiprocessing.set_sharing_strategy('file_system')\n    \n    #Initialise dataloaders\n    val_loader = get_flair_dataloader(flair_path=path_data,\n                                      num_workers=num_workers,\n                                      bm_path=path_bm)\n    \n    #Load trained models\n    K = num_models\n    models = []\n    for i in range(K):\n        models.append(SegResNet(\n            spatial_dims=3,\n            in_channels=1,\n            out_channels=2).to(device))\n    \n    if(get_default_device() == torch.device('cpu')):\n        for i, model in enumerate(models):\n            model.load_state_dict(torch.load(os.path.join(path_model,\n                                                      \"Best_model_finetuning.pth\"),\n                                                      map_location=torch.device('cpu')))\n            model.eval()\n    else :\n        for i, model in enumerate(models):\n            model.load_state_dict(torch.load(os.path.join(path_model,\n                                                      \"Best_model_finetuning.pth\")))\n            model.eval()\n            \n    act = torch.nn.Softmax(dim=1)\n    th = threshold\n    roi_size = (96, 96, 96)\n    sw_batch_size = 4\n    \n    #Predictions loop\n    with torch.no_grad():\n        for count, batch_data in enumerate(val_loader):\n            inputs = batch_data[\"image\"].to(device)\n            foreground_mask = batch_data[\"brain_mask\"].numpy()[0, 0]\n\n            # get ensemble predictions\n            all_outputs = []\n            for model in models:\n                outputs = sliding_window_inference(inputs, roi_size, sw_batch_size, model, mode='gaussian')\n                outputs = act(outputs).cpu().numpy()\n                outputs = np.squeeze(outputs[0, 1])\n                all_outputs.append(outputs)\n            all_outputs = np.asarray(all_outputs)\n\n            # get image metadata\n            original_affine = batch_data['image_meta_dict']['original_affine'][0]\n            affine = batch_data['image_meta_dict']['affine'][0]\n            spatial_shape = batch_data['image_meta_dict']['spatial_shape'][0]\n            filename_or_obj = batch_data['image_meta_dict']['filename_or_obj'][0]\n            filename_or_obj = os.path.basename(filename_or_obj)\n\n            # obtain and save probability maps averaged across models in an ensemble\n            outputs_mean = np.mean(all_outputs, axis=0)\n\n            filename = re.sub(\"FLAIR_isovox.nii\", 'pred_prob.nii.gz',\n                              filename_or_obj)\n            filepath = os.path.join(path_pred, filename)\n            write_nifti(outputs_mean, filepath,\n                        affine=original_affine,\n                        target_affine=affine,\n                        output_spatial_shape=spatial_shape)\n\n            # obtain and save binary segmentation masks\n            seg = outputs_mean.copy()\n            seg[seg >= th] = 1\n            seg[seg < th] = 0\n            seg = np.squeeze(seg)\n            seg = remove_connected_components(seg)\n\n            filename = re.sub(\"FLAIR_isovox.nii\", 'pred_seg.nii.gz',\n                              filename_or_obj)\n            filepath = os.path.join(path_pred, filename)\n            write_nifti(seg, filepath,\n                        affine=original_affine,\n                        target_affine=affine,\n                        mode='nearest',\n                        output_spatial_shape=spatial_shape)\n\n            # obtain and save uncertainty map (voxel-wise reverse mutual information)\n            uncs_map = ensemble_uncertainties_classification(np.concatenate(\n                (np.expand_dims(all_outputs, axis=-1),\n                 np.expand_dims(1. - all_outputs, axis=-1)),\n                axis=-1))['expected_entropy']\n\n            filename = re.sub(\"FLAIR_isovox.nii\", 'uncs_rmi.nii.gz',\n                              filename_or_obj)\n            filepath = os.path.join(path_pred, filename)\n            write_nifti(uncs_map * foreground_mask, filepath,\n                        affine=original_affine,\n                        target_affine=affine,\n                        output_spatial_shape=spatial_shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:28:15.163944Z","iopub.execute_input":"2024-05-03T09:28:15.164264Z","iopub.status.idle":"2024-05-03T09:28:15.184574Z","shell.execute_reply.started":"2024-05-03T09:28:15.164235Z","shell.execute_reply":"2024-05-03T09:28:15.183705Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Using the model","metadata":{}},{"cell_type":"code","source":"mkdir '/kaggle/working/predictions'","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:28:15.186457Z","iopub.execute_input":"2024-05-03T09:28:15.186980Z","iopub.status.idle":"2024-05-03T09:28:16.153695Z","shell.execute_reply.started":"2024-05-03T09:28:15.186949Z","shell.execute_reply":"2024-05-03T09:28:16.152095Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory '/kaggle/working/predictions': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"path_pred = '/kaggle/working/predictions'\npath_data = \"/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Test/FLAIR\"\npath_bm = \"/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Test/FgMasks\"\npath_model = \"/kaggle/input/segresnet/SegResNet\"\ninferenceUNET(path_pred, path_data, path_bm, threshold = 0.35, num_models = 1, path_model = path_model, num_workers = 1)\nprint(\"All Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:28:16.157023Z","iopub.execute_input":"2024-05-03T09:28:16.157344Z","iopub.status.idle":"2024-05-03T09:32:16.797044Z","shell.execute_reply.started":"2024-05-03T09:28:16.157314Z","shell.execute_reply":"2024-05-03T09:32:16.795883Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Got CUDA!\nNumber of FLAIR files: 33\n","output_type":"stream"},{"name":"stderr","text":"Loading dataset: 100%|██████████| 3/3 [00:03<00:00,  1.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"Got CUDA!\nAll Done!\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r predictions.zip '/kaggle/working/predictions'","metadata":{"execution":{"iopub.status.busy":"2024-05-03T09:33:55.129119Z","iopub.execute_input":"2024-05-03T09:33:55.130039Z","iopub.status.idle":"2024-05-03T09:34:37.316389Z","shell.execute_reply.started":"2024-05-03T09:33:55.129995Z","shell.execute_reply":"2024-05-03T09:34:37.315382Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/predictions/ (stored 0%)\n  adding: kaggle/working/predictions/8_pred_seg.nii.gz (deflated 96%)\n  adding: kaggle/working/predictions/14_pred_seg.nii.gz (deflated 91%)\n  adding: kaggle/working/predictions/26_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/13_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/28_uncs_rmi.nii.gz (deflated 1%)\n  adding: kaggle/working/predictions/33_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/8_uncs_rmi.nii.gz (deflated 2%)\n  adding: kaggle/working/predictions/3_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/22_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/4_pred_seg.nii.gz (deflated 99%)\n  adding: kaggle/working/predictions/32_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/24_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/11_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/8_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/31_pred_seg.nii.gz (deflated 89%)\n  adding: kaggle/working/predictions/21_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/11_pred_seg.nii.gz (deflated 97%)\n  adding: kaggle/working/predictions/9_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/18_pred_seg.nii.gz (deflated 97%)\n  adding: kaggle/working/predictions/1_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/31_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/22_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/20_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/1_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/23_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/10_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/1_pred_seg.nii.gz (deflated 82%)\n  adding: kaggle/working/predictions/29_pred_seg.nii.gz (deflated 89%)\n  adding: kaggle/working/predictions/15_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/19_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/17_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/7_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/19_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/14_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/30_uncs_rmi.nii.gz (deflated 2%)\n  adding: kaggle/working/predictions/23_pred_seg.nii.gz (deflated 98%)\n  adding: kaggle/working/predictions/5_pred_seg.nii.gz (deflated 95%)\n  adding: kaggle/working/predictions/16_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/32_pred_seg.nii.gz (deflated 88%)\n  adding: kaggle/working/predictions/24_uncs_rmi.nii.gz (deflated 4%)\n  adding: kaggle/working/predictions/6_pred_seg.nii.gz (deflated 81%)\n  adding: kaggle/working/predictions/18_uncs_rmi.nii.gz (deflated 2%)\n  adding: kaggle/working/predictions/27_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/18_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/3_pred_seg.nii.gz (deflated 86%)\n  adding: kaggle/working/predictions/9_pred_seg.nii.gz (deflated 94%)\n  adding: kaggle/working/predictions/28_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/25_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/33_pred_seg.nii.gz (deflated 87%)\n  adding: kaggle/working/predictions/12_pred_seg.nii.gz (deflated 98%)\n  adding: kaggle/working/predictions/4_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/24_pred_seg.nii.gz (deflated 86%)\n  adding: kaggle/working/predictions/31_uncs_rmi.nii.gz (deflated 2%)\n  adding: kaggle/working/predictions/4_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/26_pred_seg.nii.gz (deflated 88%)\n  adding: kaggle/working/predictions/14_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/21_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/21_pred_seg.nii.gz (deflated 88%)\n  adding: kaggle/working/predictions/17_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/22_pred_seg.nii.gz (deflated 83%)\n  adding: kaggle/working/predictions/28_pred_seg.nii.gz (deflated 89%)\n  adding: kaggle/working/predictions/17_pred_seg.nii.gz (deflated 96%)\n  adding: kaggle/working/predictions/2_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/12_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/27_uncs_rmi.nii.gz (deflated 1%)\n  adding: kaggle/working/predictions/12_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/11_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/32_uncs_rmi.nii.gz (deflated 2%)\n  adding: kaggle/working/predictions/25_pred_seg.nii.gz (deflated 86%)\n  adding: kaggle/working/predictions/29_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/7_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/26_uncs_rmi.nii.gz (deflated 1%)\n  adding: kaggle/working/predictions/13_pred_seg.nii.gz (deflated 86%)\n  adding: kaggle/working/predictions/19_pred_seg.nii.gz (deflated 84%)\n  adding: kaggle/working/predictions/29_uncs_rmi.nii.gz (deflated 1%)\n  adding: kaggle/working/predictions/30_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/16_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/5_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/13_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/27_pred_seg.nii.gz (deflated 88%)\n  adding: kaggle/working/predictions/6_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/9_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/3_uncs_rmi.nii.gz (deflated 4%)\n  adding: kaggle/working/predictions/23_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/7_pred_seg.nii.gz (deflated 93%)\n  adding: kaggle/working/predictions/10_uncs_rmi.nii.gz (deflated 3%)\n  adding: kaggle/working/predictions/33_uncs_rmi.nii.gz (deflated 2%)\n  adding: kaggle/working/predictions/6_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/2_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/25_uncs_rmi.nii.gz (deflated 1%)\n  adding: kaggle/working/predictions/16_pred_seg.nii.gz (deflated 89%)\n  adding: kaggle/working/predictions/5_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/15_uncs_rmi.nii.gz (deflated 2%)\n  adding: kaggle/working/predictions/15_pred_seg.nii.gz (deflated 83%)\n  adding: kaggle/working/predictions/2_pred_seg.nii.gz (deflated 95%)\n  adding: kaggle/working/predictions/10_pred_seg.nii.gz (deflated 86%)\n  adding: kaggle/working/predictions/20_pred_prob.nii.gz (deflated 0%)\n  adding: kaggle/working/predictions/20_pred_seg.nii.gz (deflated 97%)\n  adding: kaggle/working/predictions/30_pred_seg.nii.gz (deflated 88%)\n","output_type":"stream"}]}]}