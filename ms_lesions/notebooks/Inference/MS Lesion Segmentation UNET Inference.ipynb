{"cells":[{"cell_type":"markdown","metadata":{},"source":["# MS Lesion Segmentation UNET Inference"]},{"cell_type":"markdown","metadata":{},"source":["Perform inference for an ensemble of models:\n","* save 3D Nifti images of predicted probability maps averaged across ensemble models (saved to \"*pred_prob.nii.gz\" files), \n","* binary segmentation maps predicted obtained by thresholding of average predictions and removing all connected components smaller than 9 voxels (saved to \"pred_seg.nii.gz\"), \n","* uncertainty maps for reversed mutual information measure (saved to \"uncs_rmi.nii.gz\")."]},{"cell_type":"markdown","metadata":{},"source":["## Install libraries "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:40:52.179463Z","iopub.status.busy":"2024-04-26T15:40:52.178727Z","iopub.status.idle":"2024-04-26T15:41:06.664818Z","shell.execute_reply":"2024-04-26T15:41:06.663718Z","shell.execute_reply.started":"2024-04-26T15:40:52.179431Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting monai==0.9.0\n","  Downloading monai-0.9.0-202206131636-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from monai==0.9.0) (2.1.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from monai==0.9.0) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (2024.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->monai==0.9.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->monai==0.9.0) (1.3.0)\n","Downloading monai-0.9.0-202206131636-py3-none-any.whl (939 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: monai\n","Successfully installed monai-0.9.0\n"]}],"source":["!pip install monai==0.9.0"]},{"cell_type":"markdown","metadata":{},"source":["## Libraries import"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:41:06.667046Z","iopub.status.busy":"2024-04-26T15:41:06.666736Z","iopub.status.idle":"2024-04-26T15:41:43.318501Z","shell.execute_reply":"2024-04-26T15:41:43.317664Z","shell.execute_reply.started":"2024-04-26T15:41:06.667017Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-26 15:41:35.252519: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-26 15:41:35.252624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-26 15:41:35.384221: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import os\n","import re\n","import torch\n","import numpy as np\n","from glob import glob\n","from monai.inferers import sliding_window_inference\n","from monai.networks.nets import UNet\n","from monai.data import write_nifti\n","from monai.data import CacheDataset, DataLoader\n","from monai.transforms import (\n","    AddChanneld, Compose, LoadImaged, RandCropByPosNegLabeld,\n","    Spacingd, ToTensord, NormalizeIntensityd, RandFlipd,\n","    RandRotate90d, RandShiftIntensityd, RandAffined, RandSpatialCropd,\n","    RandScaleIntensityd)\n","from scipy import ndimage\n","#from data_load import remove_connected_components, get_flair_dataloader\n","#from uncertainty import ensemble_uncertainties_classification"]},{"cell_type":"markdown","metadata":{},"source":["## Setup functions"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:41:43.320217Z","iopub.status.busy":"2024-04-26T15:41:43.319602Z","iopub.status.idle":"2024-04-26T15:41:43.325451Z","shell.execute_reply":"2024-04-26T15:41:43.324287Z","shell.execute_reply.started":"2024-04-26T15:41:43.320190Z"},"trusted":true},"outputs":[],"source":["def get_default_device():\n","    \"\"\" Set device \"\"\"\n","    if torch.cuda.is_available():\n","        print(\"Got CUDA!\")\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')"]},{"cell_type":"markdown","metadata":{},"source":["### Data load"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:41:43.328829Z","iopub.status.busy":"2024-04-26T15:41:43.328159Z","iopub.status.idle":"2024-04-26T15:41:43.337000Z","shell.execute_reply":"2024-04-26T15:41:43.336097Z","shell.execute_reply.started":"2024-04-26T15:41:43.328803Z"},"trusted":true},"outputs":[],"source":["def get_val_transforms(keys=[\"image\", \"label\"], image_keys=[\"image\"]):\n","    \"\"\" Get transforms for testing on FLAIR images and ground truth:\n","    - Loads 3D images and masks from Nifti file\n","    - Adds channel dimention\n","    - Applies intensity normalisation to scans\n","    - Converts to torch.Tensor()\n","    \"\"\"\n","    return Compose(\n","        [\n","            LoadImaged(keys=keys),\n","            AddChanneld(keys=keys),\n","            NormalizeIntensityd(keys=image_keys, nonzero=True),\n","            ToTensord(keys=keys),\n","        ]\n","    )"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:41:43.338229Z","iopub.status.busy":"2024-04-26T15:41:43.337980Z","iopub.status.idle":"2024-04-26T15:41:43.348473Z","shell.execute_reply":"2024-04-26T15:41:43.347699Z","shell.execute_reply.started":"2024-04-26T15:41:43.338207Z"},"trusted":true},"outputs":[],"source":["def get_flair_dataloader(flair_path, num_workers, cache_rate=0.1, bm_path=None):\n","    \"\"\"\n","    Get dataloader with FLAIR images only for inference\n","    \n","    Args:\n","      flair_path: `str`, path to directory with FLAIR images from Train set.\n","      num_workers:  `int`,  number of worker threads to use for parallel processing\n","                    of images\n","      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n","      bm_path:   `None|str`. If `str`, then defines path to directory with\n","                 brain masks. If `None`, dataloader does not return brain masks.\n","    Returns:\n","      monai.data.DataLoader() class object.\n","    \"\"\"\n","    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii\")),\n","                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n","\n","    if bm_path is not None:\n","        bms = sorted(glob(os.path.join(bm_path, \"*isovox_fg_mask.nii\")),\n","                     key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding brain masks\n","\n","        assert len(flair) == len(bms), f\"Some files must be missing: {[len(flair), len(bms)]}\"\n","\n","        files = [{\"image\": fl, \"brain_mask\": bm} for fl, bm in zip(flair, bms)]\n","\n","        val_transforms = get_val_transforms(keys=[\"image\", \"brain_mask\"])\n","    else:\n","        files = [{\"image\": fl} for fl in flair]\n","\n","        val_transforms = get_val_transforms(keys=[\"image\"])\n","\n","    print(\"Number of FLAIR files:\", len(files))\n","\n","    ds = CacheDataset(data=files, transform=val_transforms,\n","                      cache_rate=cache_rate, num_workers=num_workers)\n","    return DataLoader(ds, batch_size=1, shuffle=False,\n","                      num_workers=num_workers)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:41:43.349818Z","iopub.status.busy":"2024-04-26T15:41:43.349559Z","iopub.status.idle":"2024-04-26T15:41:43.364101Z","shell.execute_reply":"2024-04-26T15:41:43.363225Z","shell.execute_reply.started":"2024-04-26T15:41:43.349796Z"},"trusted":true},"outputs":[],"source":["def remove_connected_components(segmentation, l_min=9):\n","    \"\"\"\n","    Remove all lesions with less or equal amount of voxels than `l_min` from a \n","    binary segmentation mask `segmentation`.\n","    Args:\n","      segmentation: `numpy.ndarray` of shape [H, W, D], with a binary lesions segmentation mask.\n","      l_min:  `int`, minimal amount of voxels in a lesion.\n","    Returns:\n","      Binary lesion segmentation mask (`numpy.ndarray` of shape [H, W, D])\n","      only with connected components that have more than `l_min` voxels.\n","    \"\"\"\n","    labeled_seg, num_labels = ndimage.label(segmentation)\n","    label_list = np.unique(labeled_seg)\n","    num_elements_by_lesion = ndimage.labeled_comprehension(segmentation, labeled_seg, label_list, np.sum, float, 0)\n","\n","    seg2 = np.zeros_like(segmentation)\n","    for i_el, n_el in enumerate(num_elements_by_lesion):\n","        if n_el > l_min:\n","            current_voxels = np.stack(np.where(labeled_seg == i_el), axis=1)\n","            seg2[current_voxels[:, 0],\n","                 current_voxels[:, 1],\n","                 current_voxels[:, 2]] = 1\n","    return seg2"]},{"cell_type":"markdown","metadata":{},"source":["### Uncertainty"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:41:43.365326Z","iopub.status.busy":"2024-04-26T15:41:43.365037Z","iopub.status.idle":"2024-04-26T15:41:43.380302Z","shell.execute_reply":"2024-04-26T15:41:43.379520Z","shell.execute_reply.started":"2024-04-26T15:41:43.365298Z"},"trusted":true},"outputs":[],"source":["def renyi_entropy_of_expected(probs, alpha=0.8):\n","    \"\"\"\n","    Renyi entropy is a generalised version of Shannon - the two are equivalent for alpha=1\n","    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n","    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n","    \"\"\"\n","    scale = 1. / (1. - alpha)\n","    mean_probs = np.mean(probs, axis=0)\n","    return scale * np.log( np.sum(mean_probs**alpha, axis=-1) )\n","\n","def renyi_expected_entropy(probs, alpha=0.8):\n","    \"\"\"\n","    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n","    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n","    \"\"\"\n","    scale = 1. / (1. - alpha)\n","    return np.mean( scale * np.log( np.sum(probs**alpha, axis=-1) ), axis=0)\n","\n","\n","def entropy_of_expected(probs, epsilon=1e-10):\n","    \"\"\"\n","    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n","    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n","    \"\"\"\n","    mean_probs = np.mean(probs, axis=0)\n","    log_probs = -np.log(mean_probs + epsilon)\n","    return np.sum(mean_probs * log_probs, axis=-1)\n","\n","def expected_entropy(probs, epsilon=1e-10):\n","    \"\"\"\n","    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n","    :return: array [num_voxels_X, num_voxels_Y, num_voxels_Z,]\n","    \"\"\"\n","    log_probs = -np.log(probs + epsilon)\n","    return np.mean(np.sum(probs * log_probs, axis=-1), axis=0)\n","\n","\n","def ensemble_uncertainties_classification(probs, epsilon=1e-10):\n","    \"\"\"\n","    :param probs: array [num_models, num_voxels_X, num_voxels_Y, num_voxels_Z, num_classes]\n","    :return: Dictionary of uncertainties\n","    \"\"\"\n","    mean_probs = np.mean(probs, axis=0)\n","    mean_lprobs = np.mean(np.log(probs + epsilon), axis=0)\n","    conf = np.max(mean_probs, axis=-1)\n","\n","    eoe = entropy_of_expected(probs, epsilon)\n","    exe = expected_entropy(probs, epsilon)\n","\n","    mutual_info = eoe - exe\n","\n","    epkl = -np.sum(mean_probs * mean_lprobs, axis=-1) - exe\n","\n","    uncertainty = {'confidence': -1 * conf,\n","                   'entropy_of_expected': eoe,\n","                   'expected_entropy': exe,\n","                   'mutual_information': mutual_info,\n","                   'epkl': epkl,\n","                   'reverse_mutual_information': epkl - mutual_info,\n","                   }\n","\n","    return uncertainty"]},{"cell_type":"markdown","metadata":{},"source":["### Inference function"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:57:31.819708Z","iopub.status.busy":"2024-04-26T15:57:31.818826Z","iopub.status.idle":"2024-04-26T15:57:31.840417Z","shell.execute_reply":"2024-04-26T15:57:31.839354Z","shell.execute_reply.started":"2024-04-26T15:57:31.819669Z"},"trusted":true},"outputs":[],"source":["def inferenceUNET(path_pred, path_data, path_bm, threshold = 0.35, num_models = 3, path_model = '', num_workers = 1):\n","    \n","    #Setting up output directory\n","    os.makedirs(path_pred, exist_ok=True)\n","    \n","    #Settin up device\n","    device = get_default_device()\n","    torch.multiprocessing.set_sharing_strategy('file_system')\n","    \n","    #Initialise dataloaders\n","    val_loader = get_flair_dataloader(flair_path=path_data,\n","                                      num_workers=num_workers,\n","                                      bm_path=path_bm)\n","    \n","    #Load trained models\n","    K = num_models\n","    models = []\n","    for i in range(K):\n","        models.append(UNet(\n","            spatial_dims=3,\n","            in_channels=1,\n","            out_channels=2,\n","            channels=(32, 64, 128, 256, 512),\n","            strides=(2, 2, 2, 2),\n","            num_res_units=0).to(device))\n","    \n","    if(get_default_device() == torch.device('cpu')):\n","        for i, model in enumerate(models):\n","            model.load_state_dict(torch.load(os.path.join(path_model,\n","                                                      f\"seed{i + 1}\",\n","                                                      \"Best_model_finetuning.pth\"),\n","                                                      map_location=torch.device('cpu')))\n","            model.eval()\n","    else :\n","        for i, model in enumerate(models):\n","            model.load_state_dict(torch.load(os.path.join(path_model,\n","                                                      f\"seed{i + 1}\",\n","                                                      \"Best_model_finetuning.pth\")))\n","            model.eval()\n","            \n","    act = torch.nn.Softmax(dim=1)\n","    th = threshold\n","    roi_size = (96, 96, 96)\n","    sw_batch_size = 4\n","    \n","    #Predictions loop\n","    with torch.no_grad():\n","        for count, batch_data in enumerate(val_loader):\n","            inputs = batch_data[\"image\"].to(device)\n","            foreground_mask = batch_data[\"brain_mask\"].numpy()[0, 0]\n","\n","            # get ensemble predictions\n","            all_outputs = []\n","            for model in models:\n","                outputs = sliding_window_inference(inputs, roi_size, sw_batch_size, model, mode='gaussian')\n","                outputs = act(outputs).cpu().numpy()\n","                outputs = np.squeeze(outputs[0, 1])\n","                all_outputs.append(outputs)\n","            all_outputs = np.asarray(all_outputs)\n","\n","            # get image metadata\n","            original_affine = batch_data['image_meta_dict']['original_affine'][0]\n","            affine = batch_data['image_meta_dict']['affine'][0]\n","            spatial_shape = batch_data['image_meta_dict']['spatial_shape'][0]\n","            filename_or_obj = batch_data['image_meta_dict']['filename_or_obj'][0]\n","            filename_or_obj = os.path.basename(filename_or_obj)\n","\n","            # obtain and save probability maps averaged across models in an ensemble\n","            outputs_mean = np.mean(all_outputs, axis=0)\n","\n","            filename = re.sub(\"FLAIR_isovox.nii\", 'pred_prob.nii.gz',\n","                              filename_or_obj)\n","            filepath = os.path.join(path_pred, filename)\n","            write_nifti(outputs_mean, filepath,\n","                        affine=original_affine,\n","                        target_affine=affine,\n","                        output_spatial_shape=spatial_shape)\n","\n","            # obtain and save binary segmentation masks\n","            seg = outputs_mean.copy()\n","            seg[seg >= th] = 1\n","            seg[seg < th] = 0\n","            seg = np.squeeze(seg)\n","            seg = remove_connected_components(seg)\n","\n","            filename = re.sub(\"FLAIR_isovox.nii\", 'pred_seg.nii.gz',\n","                              filename_or_obj)\n","            filepath = os.path.join(path_pred, filename)\n","            write_nifti(seg, filepath,\n","                        affine=original_affine,\n","                        target_affine=affine,\n","                        mode='nearest',\n","                        output_spatial_shape=spatial_shape)\n","\n","            # obtain and save uncertainty map (voxel-wise reverse mutual information)\n","            uncs_map = ensemble_uncertainties_classification(np.concatenate(\n","                (np.expand_dims(all_outputs, axis=-1),\n","                 np.expand_dims(1. - all_outputs, axis=-1)),\n","                axis=-1))['reverse_mutual_information']\n","\n","            filename = re.sub(\"FLAIR_isovox.nii\", 'uncs_rmi.nii.gz',\n","                              filename_or_obj)\n","            filepath = os.path.join(path_pred, filename)\n","            write_nifti(uncs_map * foreground_mask, filepath,\n","                        affine=original_affine,\n","                        target_affine=affine,\n","                        output_spatial_shape=spatial_shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Using the model"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T15:59:46.735977Z","iopub.status.busy":"2024-04-26T15:59:46.735595Z","iopub.status.idle":"2024-04-26T16:03:14.895121Z","shell.execute_reply":"2024-04-26T16:03:14.893974Z","shell.execute_reply.started":"2024-04-26T15:59:46.735948Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Got CUDA!\n","Number of FLAIR files: 33\n"]},{"name":"stderr","output_type":"stream","text":["Loading dataset: 100%|██████████| 3/3 [00:00<00:00,  5.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Got CUDA!\n","All Done!\n"]}],"source":["path_pred = '/kaggle/working/predictions'\n","path_data = \"/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Test/FLAIR\"\n","path_bm = \"/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Test/FgMasks\"\n","path_model = \"/kaggle/input/sdcombinedextracted/baselinetrained\"\n","inferenceUNET(path_pred, path_data, path_bm, threshold = 0.35, num_models = 1, path_model = path_model, num_workers = 1)\n","print(\"All Done!\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4826829,"sourceId":8166514,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
