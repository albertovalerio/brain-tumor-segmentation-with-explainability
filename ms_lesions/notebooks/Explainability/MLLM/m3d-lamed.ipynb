{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8166514,"sourceType":"datasetVersion","datasetId":4826829},{"sourceId":8383072,"sourceType":"datasetVersion","datasetId":4985482}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/BAAI-DCAI/M3D.git\n!pip install -r /kaggle/working/M3D/requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install simple_slice_viewer\n!pip install monai\n!pip install einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport nibabel as nib\n\n# 1. Load the .nii image\nimage_path = \"/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Test/FLAIR/1_FLAIR_isovox.nii\"\nimage = nib.load(image_path)\nimage_data = image.get_fdata()\n\n# 2. Resize the image to 1*32*256*256\nresized_image_data = np.resize(image_data, (1, 32, 256, 256))\n\n# 3. Normalize the image to 0-1 using Min-Max Normalization\nmin_value = np.min(resized_image_data)\nmax_value = np.max(resized_image_data)\nnormalized_image_data = (resized_image_data - min_value) / (max_value - min_value)\n\n# 4. Save the normalized image as .npy\noutput_path = \"/kaggle/working/normalized_image.npy\"\nnp.save(output_path, normalized_image_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport simple_slice_viewer as ssv\nimport SimpleITK as sikt\n\ndevice = torch.device('cuda') # 'cpu', 'cuda'\ndtype = torch.bfloat16 # or bfloat16, float16, float32\n\nmodel_name_or_path = 'GoodBaiBai88/M3D-LaMed-Llama-2-7B'\nproj_out_num = 256\n\n# Prepare your 3D medical image:\n# 1. The image shape needs to be processed as 1*32*256*256, consider resize and other methods.\n# 2. The image needs to be normalized to 0-1, consider Min-Max Normalization.\n# 3. The image format needs to be converted to .npy \n# 4. Although we did not train on 2D images, in theory, the 2D image can be interpolated to the shape of 1*32*256*256 for input.\nimage_path = \"/kaggle/working/normalized_image.npy\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name_or_path,\n    torch_dtype=dtype,\n    device_map='auto',\n    trust_remote_code=True)\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name_or_path,\n    model_max_length=512,\n    padding_side=\"right\",\n    use_fast=False,\n    trust_remote_code=True\n)\n\nmodel = model.to(device=device)\n\n# question = \"Can you provide a caption consists of findings for this medical image?\"\nquestion = \"What is liver in this image? Please output the segmentation mask.\"\n# question = \"What is liver in this image? Please output the box.\"\n\nimage_tokens = \"<im_patch>\" * proj_out_num\ninput_txt = image_tokens + question\ninput_id = tokenizer(input_txt, return_tensors=\"pt\")['input_ids'].to(device=device)\n\nimage_np = np.load(image_path)\nimage_pt = torch.from_numpy(image_np).unsqueeze(0).to(dtype=dtype, device=device)\n\n# generation = model.generate(image_pt, input_id, max_new_tokens=256, do_sample=True, top_p=0.9, temperature=1.0)\ngeneration, seg_logit = model.generate(image_pt, input_id, seg_enable=True, max_new_tokens=256, do_sample=True, top_p=0.9, temperature=1.0)\n\ngenerated_texts = tokenizer.batch_decode(generation, skip_special_tokens=True)\nseg_mask = (torch.sigmoid(seg_logit) > 0.5) * 1.0\n\nprint('question', question)\nprint('generated_texts', generated_texts[0])\n\nimage = sikt.GetImageFromArray(image_np)\nssv.display(image)\nseg = sikt.GetImageFromArray(seg_mask.cpu().numpy()[0])\nssv.display(seg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}