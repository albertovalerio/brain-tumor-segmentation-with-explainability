{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **MS LESION SEGMENTATION TRAINING UNET** "]},{"cell_type":"markdown","metadata":{},"source":["## Install Libraries"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:24:17.539604Z","iopub.status.busy":"2024-04-24T14:24:17.539110Z","iopub.status.idle":"2024-04-24T14:24:36.554473Z","shell.execute_reply":"2024-04-24T14:24:36.553249Z","shell.execute_reply.started":"2024-04-24T14:24:17.539531Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting monai==0.9.0\n","  Downloading monai-0.9.0-202206131636-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from monai==0.9.0) (2.1.2+cpu)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from monai==0.9.0) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (2024.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->monai==0.9.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->monai==0.9.0) (1.3.0)\n","Downloading monai-0.9.0-202206131636-py3-none-any.whl (939 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hInstalling collected packages: monai\n","Successfully installed monai-0.9.0\n"]}],"source":["!pip install monai==0.9.0\n","!pip install torch\n","!pip install tqdm\n","!pip install scipy"]},{"cell_type":"markdown","metadata":{},"source":["## Libraries Import"]},{"cell_type":"code","execution_count":25,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-24T14:30:59.995355Z","iopub.status.busy":"2024-04-24T14:30:59.994884Z","iopub.status.idle":"2024-04-24T14:31:00.004780Z","shell.execute_reply":"2024-04-24T14:31:00.002670Z","shell.execute_reply.started":"2024-04-24T14:30:59.995319Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from monai.inferers import sliding_window_inference\n","from monai.losses import DiceLoss\n","from monai.networks.nets import UNet\n","import numpy as np\n","import random\n","import os\n","from glob import glob\n","import re\n","from monai.data import CacheDataset, DataLoader\n","from monai.transforms import (\n","    AddChanneld, Compose, LoadImaged, RandCropByPosNegLabeld,\n","    Spacingd, ToTensord, NormalizeIntensityd, RandFlipd,\n","    RandRotate90d, RandShiftIntensityd, RandAffined, RandSpatialCropd,\n","    RandScaleIntensityd)\n","from scipy import ndimage"]},{"cell_type":"markdown","metadata":{},"source":["## Setup Functions"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:27:27.060468Z","iopub.status.busy":"2024-04-24T14:27:27.060003Z","iopub.status.idle":"2024-04-24T14:27:27.067287Z","shell.execute_reply":"2024-04-24T14:27:27.065495Z","shell.execute_reply.started":"2024-04-24T14:27:27.060428Z"},"trusted":true},"outputs":[],"source":["def get_default_device():\n","    \"\"\" Set device \"\"\"\n","    if torch.cuda.is_available():\n","        print(\"Got CUDA!\")\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def dice_metric(ground_truth, predictions):\n","    \"\"\"\n","    Compute Dice coefficient for a single example.\n","    Args:\n","      ground_truth: `numpy.ndarray`, binary ground truth segmentation target,\n","                     with shape [W, H, D].\n","      predictions:  `numpy.ndarray`, binary segmentation predictions,\n","                     with shape [W, H, D].\n","    Returns:\n","      Dice coefficient overlap (`float` in [0.0, 1.0])\n","      between `ground_truth` and `predictions`.\n","    \"\"\"\n","    # Calculate intersection and union of y_true and y_predict\n","    intersection = np.sum(predictions * ground_truth)\n","    union = np.sum(predictions) + np.sum(ground_truth)\n","\n","    # Calcualte dice metric\n","    if intersection == 0.0 and union == 0.0:\n","        dice = 1.0\n","    else:\n","        dice = (2. * intersection) / union\n","\n","    return dice"]},{"cell_type":"markdown","metadata":{},"source":["### Data Load Functions"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:30:25.098882Z","iopub.status.busy":"2024-04-24T14:30:25.098405Z","iopub.status.idle":"2024-04-24T14:30:25.112979Z","shell.execute_reply":"2024-04-24T14:30:25.111484Z","shell.execute_reply.started":"2024-04-24T14:30:25.098848Z"},"trusted":true},"outputs":[],"source":["def get_train_transforms():\n","    \"\"\" Get transforms for training on FLAIR images and ground truth:\n","    - Loads 3D images from Nifti file\n","    - Adds channel dimention\n","    - Normalises intensity\n","    - Applies augmentations\n","    - Crops out 32 patches of shape [96, 96, 96] that contain lesions\n","    - Converts to torch.Tensor()\n","    \"\"\"\n","    return Compose(\n","        [\n","            LoadImaged(keys=[\"image\", \"label\"]),\n","            AddChanneld(keys=[\"image\", \"label\"]),\n","            NormalizeIntensityd(keys=[\"image\"], nonzero=True),\n","            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n","            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n","            RandCropByPosNegLabeld(keys=[\"image\", \"label\"],\n","                                   label_key=\"label\", image_key=\"image\",\n","                                   spatial_size=(128, 128, 128), num_samples=32,\n","                                   pos=4, neg=1),\n","            RandSpatialCropd(keys=[\"image\", \"label\"],\n","                             roi_size=(96, 96, 96),\n","                             random_center=True, random_size=False),\n","            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=(0, 1, 2)),\n","            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 1)),\n","            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(1, 2)),\n","            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 2)),\n","            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'),\n","                        prob=1.0, spatial_size=(96, 96, 96),\n","                        rotate_range=(np.pi / 12, np.pi / 12, np.pi / 12),\n","                        scale_range=(0.1, 0.1, 0.1), padding_mode='border'),\n","            ToTensord(keys=[\"image\", \"label\"]),\n","        ]\n","    )"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:31:44.327984Z","iopub.status.busy":"2024-04-24T14:31:44.326612Z","iopub.status.idle":"2024-04-24T14:31:44.335886Z","shell.execute_reply":"2024-04-24T14:31:44.333927Z","shell.execute_reply.started":"2024-04-24T14:31:44.327928Z"},"trusted":true},"outputs":[],"source":["def get_val_transforms(keys=[\"image\", \"label\"], image_keys=[\"image\"]):\n","    \"\"\" Get transforms for testing on FLAIR images and ground truth:\n","    - Loads 3D images and masks from Nifti file\n","    - Adds channel dimention\n","    - Applies intensity normalisation to scans\n","    - Converts to torch.Tensor()\n","    \"\"\"\n","    return Compose(\n","        [\n","            LoadImaged(keys=keys),\n","            AddChanneld(keys=keys),\n","            NormalizeIntensityd(keys=image_keys, nonzero=True),\n","            ToTensord(keys=keys),\n","        ]\n","    )"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:29:44.337730Z","iopub.status.busy":"2024-04-24T14:29:44.337217Z","iopub.status.idle":"2024-04-24T14:29:44.347943Z","shell.execute_reply":"2024-04-24T14:29:44.346713Z","shell.execute_reply.started":"2024-04-24T14:29:44.337689Z"},"trusted":true},"outputs":[],"source":["def get_train_dataloader(flair_path, gts_path, num_workers, cache_rate=0.1):\n","    \"\"\"\n","    Get dataloader for training \n","    Args:\n","      flair_path: `str`, path to directory with FLAIR images from Train set.\n","      gts_path:  `str`, path to directory with ground truth lesion segmentation \n","                    binary masks images from Train set.\n","      num_workers:  `int`,  number of worker threads to use for parallel processing\n","                    of images\n","      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n","    Returns:\n","      monai.data.DataLoader() class object.\n","    \"\"\"\n","    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii.*\")),\n","                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n","    segs = sorted(glob(os.path.join(gts_path, \"*gt_isovox.nii.*\")),\n","                  key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding ground truths\n","\n","    files = [{\"image\": fl, \"label\": seg} for fl, seg in zip(flair, segs)]\n","\n","    print(\"Number of training files:\", len(files))\n","\n","    ds = CacheDataset(data=files, transform=get_train_transforms(),\n","                      cache_rate=cache_rate, num_workers=num_workers)\n","    return DataLoader(ds, batch_size=1, shuffle=True,\n","                      num_workers=num_workers)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:27:30.909451Z","iopub.status.busy":"2024-04-24T14:27:30.907835Z","iopub.status.idle":"2024-04-24T14:27:30.925188Z","shell.execute_reply":"2024-04-24T14:27:30.923387Z","shell.execute_reply.started":"2024-04-24T14:27:30.909383Z"},"trusted":true},"outputs":[],"source":["def get_val_dataloader(flair_path, gts_path, num_workers, cache_rate=0.1, bm_path=None):\n","    \"\"\"\n","    Get dataloader for validation and testing. Either with or without brain masks.\n","\n","    Args:\n","      flair_path: `str`, path to directory with FLAIR images.\n","      gts_path:  `str`, path to directory with ground truth lesion segmentation \n","                    binary masks images.\n","      num_workers:  `int`,  number of worker threads to use for parallel processing\n","                    of images\n","      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n","      bm_path:   `None|str`. If `str`, then defines path to directory with\n","                 brain masks. If `None`, dataloader does not return brain masks. \n","    Returns:\n","      monai.data.DataLoader() class object.\n","    \"\"\"\n","    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii.*\")),\n","                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n","    segs = sorted(glob(os.path.join(gts_path, \"*_isovox.nii.*\")),\n","                  key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding ground truths\n","\n","    if bm_path is not None:\n","        bms = sorted(glob(os.path.join(bm_path, \"*isovox_fg_mask.nii.*\")),\n","                     key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding brain masks\n","\n","        assert len(flair) == len(segs) == len(bms), f\"Some files must be missing: {[len(flair), len(segs), len(bms)]}\"\n","\n","        files = [\n","            {\"image\": fl, \"label\": seg, \"brain_mask\": bm} for fl, seg, bm\n","            in zip(flair, segs, bms)\n","        ]\n","\n","        val_transforms = get_val_transforms(keys=[\"image\", \"label\", \"brain_mask\"])\n","    else:\n","        assert len(flair) == len(segs), f\"Some files must be missing: {[len(flair), len(segs)]}\"\n","\n","        files = [{\"image\": fl, \"label\": seg} for fl, seg in zip(flair, segs)]\n","\n","        val_transforms = get_val_transforms()\n","\n","    print(\"Number of validation files:\", len(files))\n","\n","    ds = CacheDataset(data=files, transform=val_transforms,\n","                      cache_rate=cache_rate, num_workers=num_workers)\n","    return DataLoader(ds, batch_size=1, shuffle=False,\n","                      num_workers=num_workers)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:32:14.291004Z","iopub.status.busy":"2024-04-24T14:32:14.290502Z","iopub.status.idle":"2024-04-24T14:32:14.303942Z","shell.execute_reply":"2024-04-24T14:32:14.302775Z","shell.execute_reply.started":"2024-04-24T14:32:14.290965Z"},"trusted":true},"outputs":[],"source":["def get_flair_dataloader(flair_path, num_workers, cache_rate=0.1, bm_path=None):\n","    \"\"\"\n","    Get dataloader with FLAIR images only for inference\n","    \n","    Args:\n","      flair_path: `str`, path to directory with FLAIR images from Train set.\n","      num_workers:  `int`,  number of worker threads to use for parallel processing\n","                    of images\n","      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n","      bm_path:   `None|str`. If `str`, then defines path to directory with\n","                 brain masks. If `None`, dataloader does not return brain masks.\n","    Returns:\n","      monai.data.DataLoader() class object.\n","    \"\"\"\n","    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii.*\")),\n","                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n","\n","    if bm_path is not None:\n","        bms = sorted(glob(os.path.join(bm_path, \"*isovox_fg_mask.nii.*\")),\n","                     key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding brain masks\n","\n","        assert len(flair) == len(bms), f\"Some files must be missing: {[len(flair), len(bms)]}\"\n","\n","        files = [{\"image\": fl, \"brain_mask\": bm} for fl, bm in zip(flair, bms)]\n","\n","        val_transforms = get_val_transforms(keys=[\"image\", \"brain_mask\"])\n","    else:\n","        files = [{\"image\": fl} for fl in flair]\n","\n","        val_transforms = get_val_transforms(keys=[\"image\"])\n","\n","    print(\"Number of FLAIR files:\", len(files))\n","\n","    ds = CacheDataset(data=files, transform=val_transforms,\n","                      cache_rate=cache_rate, num_workers=num_workers)\n","    return DataLoader(ds, batch_size=1, shuffle=False,\n","                      num_workers=num_workers)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:32:28.857936Z","iopub.status.busy":"2024-04-24T14:32:28.856914Z","iopub.status.idle":"2024-04-24T14:32:28.867228Z","shell.execute_reply":"2024-04-24T14:32:28.865924Z","shell.execute_reply.started":"2024-04-24T14:32:28.857877Z"},"trusted":true},"outputs":[],"source":["def remove_connected_components(segmentation, l_min=9):\n","    \"\"\"\n","    Remove all lesions with less or equal amount of voxels than `l_min` from a \n","    binary segmentation mask `segmentation`.\n","    Args:\n","      segmentation: `numpy.ndarray` of shape [H, W, D], with a binary lesions segmentation mask.\n","      l_min:  `int`, minimal amount of voxels in a lesion.\n","    Returns:\n","      Binary lesion segmentation mask (`numpy.ndarray` of shape [H, W, D])\n","      only with connected components that have more than `l_min` voxels.\n","    \"\"\"\n","    labeled_seg, num_labels = ndimage.label(segmentation)\n","    label_list = np.unique(labeled_seg)\n","    num_elements_by_lesion = ndimage.labeled_comprehension(segmentation, labeled_seg, label_list, np.sum, float, 0)\n","\n","    seg2 = np.zeros_like(segmentation)\n","    for i_el, n_el in enumerate(num_elements_by_lesion):\n","        if n_el > l_min:\n","            current_voxels = np.stack(np.where(labeled_seg == i_el), axis=1)\n","            seg2[current_voxels[:, 0],\n","                 current_voxels[:, 1],\n","                 current_voxels[:, 2]] = 1\n","    return seg2"]},{"cell_type":"markdown","metadata":{},"source":["## Training Function"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-04-24T14:45:27.172961Z","iopub.status.busy":"2024-04-24T14:45:27.172512Z","iopub.status.idle":"2024-04-24T14:45:27.201565Z","shell.execute_reply":"2024-04-24T14:45:27.200269Z","shell.execute_reply.started":"2024-04-24T14:45:27.172928Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Training function for UNet model with Dice and Focal loss.\n","Args:\n","    Data Args:\n","        path_train_data: `str`, path to directory with FLAIR images from Train set.\n","        path_train_gts: `str`, path to directory with ground truth lesion segmentation\n","        path_val_data: `str`, path to directory with FLAIR images from Validation set.\n","        path_val_gts: `str`, path to directory with ground truth lesion segmentation\n","    Model Args:\n","        learning_rate: `float`, learning rate for the optimizer.\n","        n_epochs: `int`, number of epochs to train the model.\n","        seed: `int`, random seed for reproducibility.\n","        threshold: `float`, probability threshold for binarization of the output.\n","        num_workers: `int`, number of worker threads to use for parallel processing\n","        path_save: `str`, path to directory where to save the best model.\n","        val_interval: `int`, interval for validation.\n","\"\"\"\n","def trainUNet(path_train_data, path_train_gts, path_val_data, path_val_gts, learning_rate = 1e-5, n_epochs = 300, seed = 42, threshold = 0.4, num_workers = 4, path_save = '', val_interval = 5):\n","    # setting up the seeds\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    \n","    # setting up the device\n","    device = get_default_device()\n","    torch.multiprocessing.set_sharing_strategy('file_system')\n","    \n","    # Initialise dataloaders\n","    train_loader = get_train_dataloader(flair_path=path_train_data, \n","                                        gts_path=path_train_gts, \n","                                        num_workers=num_workers)\n","    val_loader = get_val_dataloader(flair_path=path_val_data, \n","                                    gts_path=path_val_gts, \n","                                    num_workers=num_workers)\n","    # Initialise the model\n","    model = UNet(\n","        spatial_dims=3,\n","        in_channels=1,\n","        out_channels=2,\n","        channels=(32, 64, 128, 256, 512),\n","        strides=(2, 2, 2, 2),\n","        num_res_units=0).to(device)\n","    \n","    loss_function = DiceLoss(to_onehot_y=True, \n","                             softmax=True, sigmoid=False,\n","                             include_background=False)\n","    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n","    act = nn.Softmax(dim=1)\n","    \n","    epoch_num = n_epochs\n","    val_interval = val_interval\n","    thresh = threshold\n","    gamma_focal = 2.0\n","    dice_weight = 0.5\n","    focal_weight = 1.0\n","    roi_size = (96, 96, 96)\n","    sw_batch_size = 4\n","    \n","    best_metric, best_metric_epoch = -1, -1\n","    epoch_loss_values, metric_values = [], []\n","    \n","    # Training Loop\n","    for epoch in range(epoch_num):\n","        print(\"-\" * 10)\n","        print(f\"epoch {epoch + 1}/{epoch_num}\")\n","        model.train()\n","        epoch_loss = 0\n","        step = 0\n","        for batch_data in train_loader:\n","            n_samples = batch_data[\"image\"].size(0)\n","            for m in range(0,batch_data[\"image\"].size(0), 2):\n","                step += 2\n","                inputs, labels = (\n","                    batch_data[\"image\"][m:(m+2)].to(device),\n","                    batch_data[\"label\"][m:(m+2)].type(torch.LongTensor).to(device))\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                \n","                # Dice loss\n","                loss1 = loss_function(outputs, labels)\n","                # Focal loss\n","                ce_loss = nn.CrossEntropyLoss(reduction='none')\n","                ce = ce_loss(outputs, torch.squeeze(labels, dim=1))\n","                pt = torch.exp(-ce)\n","                loss2 = (1 - pt)**gamma_focal * ce \n","                loss2 = torch.mean(loss2)\n","                loss = dice_weight * loss1 + focal_weight * loss2              \n","                \n","                loss.backward()\n","                optimizer.step()\n","                \n","                epoch_loss += loss.item()\n","                if step % 100 == 0:\n","                    step_print = int(step/2)\n","                    print(f\"{step_print}/{(len(train_loader)*n_samples) // (train_loader.batch_size*2)}, train_loss: {loss.item():.4f}\")\n","\n","        epoch_loss /= step_print\n","        epoch_loss_values.append(epoch_loss)\n","        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","        \n","        # Validation\n","        if (epoch + 1) % val_interval == 0:\n","            model.eval()\n","            with torch.no_grad():\n","                metric_sum = 0.0\n","                metric_count = 0\n","                for val_data in val_loader:\n","                    val_inputs, val_labels = (\n","                        val_data[\"image\"].to(device),\n","                        val_data[\"label\"].to(device)\n","                        )\n","                    \n","                    val_outputs = sliding_window_inference(val_inputs, roi_size, \n","                                                           sw_batch_size, \n","                                                           model, mode='gaussian')\n","                   \n","                    gt = np.squeeze(val_labels.cpu().numpy())\n","                    \n","                    seg = act(val_outputs).cpu().numpy()\n","                    seg= np.squeeze(seg[0,1])\n","                    seg[seg >= thresh] = 1\n","                    seg[seg < thresh] = 0\n","                    \n","                    value = dice_metric(ground_truth=gt.flatten(), predictions=seg.flatten())\n","\n","                    metric_count += 1\n","                    metric_sum += value.sum().item()\n","                \n","                metric = metric_sum / metric_count\n","                metric_values.append(metric)\n","                if metric > best_metric:\n","                    best_metric = metric\n","                    best_metric_epoch = epoch + 1\n","                    torch.save(model.state_dict(), os.path.join(path_save, \"Best_model_finetuning.pth\"))\n","                    print(\"saved new best metric model\")\n","                print(f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n","                                    f\"\\nbest mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n","                                    )\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train The Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data = '/pathToData/Train/FLAIR'\n","train_gts = '/pathToData/Train/GroundTruth'\n","val_data = '/pathToData/Val/FLAIR'\n","val_data_gts = '/pathToData/Val/GroundTruth'\n","\n","trainUNet(train_data, train_gts, val_data, val_data_gts, learning_rate = 1e-5, n_epochs = 300, seed = 42, threshold = 0.4, num_workers = 10, path_save = '', val_interval = 5)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4826829,"sourceId":8166514,"sourceType":"datasetVersion"},{"datasetId":4822772,"sourceId":8153696,"sourceType":"datasetVersion"}],"dockerImageVersionId":30702,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
