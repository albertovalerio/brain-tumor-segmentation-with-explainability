{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **MS LESION SEGMENTATION TRAINING** "]},{"cell_type":"markdown","metadata":{},"source":["## Install Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:14:54.779159Z","iopub.status.busy":"2024-04-27T10:14:54.778001Z","iopub.status.idle":"2024-04-27T10:15:23.173172Z","shell.execute_reply":"2024-04-27T10:15:23.172018Z","shell.execute_reply.started":"2024-04-27T10:14:54.779093Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting monai==0.9.0\n","  Downloading monai-0.9.0-202206131636-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from monai==0.9.0) (2.1.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from monai==0.9.0) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->monai==0.9.0) (2024.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->monai==0.9.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->monai==0.9.0) (1.3.0)\n","Downloading monai-0.9.0-202206131636-py3-none-any.whl (939 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hInstalling collected packages: monai\n","Successfully installed monai-0.9.0\n","Collecting einops\n","  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n","Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.7.0\n"]}],"source":["!pip install monai==0.9.0\n","!pip install einops\n","!pip install torch\n","!pip install tqdm\n","!pip install scipy"]},{"cell_type":"markdown","metadata":{},"source":["## Libraries Import"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-27T10:15:23.176591Z","iopub.status.busy":"2024-04-27T10:15:23.175827Z","iopub.status.idle":"2024-04-27T10:15:59.195606Z","shell.execute_reply":"2024-04-27T10:15:59.194809Z","shell.execute_reply.started":"2024-04-27T10:15:23.176527Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-27 10:15:51.000462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-27 10:15:51.000566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-27 10:15:51.133993: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import torch\n","from torch import nn\n","from monai.inferers import sliding_window_inference\n","from monai.losses import DiceLoss\n","from monai.networks.nets import SwinUNETR\n","import numpy as np\n","import random\n","import os\n","from glob import glob\n","import re\n","from monai.data import CacheDataset, DataLoader\n","from monai.transforms import (\n","    AddChanneld, Compose, LoadImaged, RandCropByPosNegLabeld,\n","    Spacingd, ToTensord, NormalizeIntensityd, RandFlipd,\n","    RandRotate90d, RandShiftIntensityd, RandAffined, RandSpatialCropd,\n","    RandScaleIntensityd)\n","from scipy import ndimage"]},{"cell_type":"markdown","metadata":{},"source":["## Setup Functions"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:15:59.197382Z","iopub.status.busy":"2024-04-27T10:15:59.196705Z","iopub.status.idle":"2024-04-27T10:15:59.202490Z","shell.execute_reply":"2024-04-27T10:15:59.201403Z","shell.execute_reply.started":"2024-04-27T10:15:59.197353Z"},"trusted":true},"outputs":[],"source":["def get_default_device():\n","    \"\"\" Set device \"\"\"\n","    if torch.cuda.is_available():\n","        print(\"Got CUDA!\")\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:15:59.204790Z","iopub.status.busy":"2024-04-27T10:15:59.204486Z","iopub.status.idle":"2024-04-27T10:15:59.213995Z","shell.execute_reply":"2024-04-27T10:15:59.213250Z","shell.execute_reply.started":"2024-04-27T10:15:59.204763Z"},"trusted":true},"outputs":[],"source":["def dice_metric(ground_truth, predictions):\n","    \"\"\"\n","    Compute Dice coefficient for a single example.\n","    Args:\n","      ground_truth: `numpy.ndarray`, binary ground truth segmentation target,\n","                     with shape [W, H, D].\n","      predictions:  `numpy.ndarray`, binary segmentation predictions,\n","                     with shape [W, H, D].\n","    Returns:\n","      Dice coefficient overlap (`float` in [0.0, 1.0])\n","      between `ground_truth` and `predictions`.\n","    \"\"\"\n","    # Calculate intersection and union of y_true and y_predict\n","    intersection = np.sum(predictions * ground_truth)\n","    union = np.sum(predictions) + np.sum(ground_truth)\n","\n","    # Calcualte dice metric\n","    if intersection == 0.0 and union == 0.0:\n","        dice = 1.0\n","    else:\n","        dice = (2. * intersection) / union\n","\n","    return dice"]},{"cell_type":"markdown","metadata":{},"source":["### Data Load Functions"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:15:59.215515Z","iopub.status.busy":"2024-04-27T10:15:59.215192Z","iopub.status.idle":"2024-04-27T10:15:59.227835Z","shell.execute_reply":"2024-04-27T10:15:59.226797Z","shell.execute_reply.started":"2024-04-27T10:15:59.215484Z"},"trusted":true},"outputs":[],"source":["def get_train_transforms():\n","    \"\"\" Get transforms for training on FLAIR images and ground truth:\n","    - Loads 3D images from Nifti file\n","    - Adds channel dimention\n","    - Normalises intensity\n","    - Applies augmentations\n","    - Crops out 32 patches of shape [96, 96, 96] that contain lesions\n","    - Converts to torch.Tensor()\n","    \"\"\"\n","    return Compose(\n","        [\n","            LoadImaged(keys=[\"image\", \"label\"]),\n","            AddChanneld(keys=[\"image\", \"label\"]),\n","            NormalizeIntensityd(keys=[\"image\"], nonzero=True),\n","            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n","            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n","            RandCropByPosNegLabeld(keys=[\"image\", \"label\"],\n","                                   label_key=\"label\", image_key=\"image\",\n","                                   spatial_size=(128, 128, 128), num_samples=32,\n","                                   pos=4, neg=1),\n","            RandSpatialCropd(keys=[\"image\", \"label\"],\n","                             roi_size=(96, 96, 96),\n","                             random_center=True, random_size=False),\n","            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=(0, 1, 2)),\n","            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 1)),\n","            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(1, 2)),\n","            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 2)),\n","            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'),\n","                        prob=1.0, spatial_size=(96, 96, 96),\n","                        rotate_range=(np.pi / 12, np.pi / 12, np.pi / 12),\n","                        scale_range=(0.1, 0.1, 0.1), padding_mode='border'),\n","            ToTensord(keys=[\"image\", \"label\"]),\n","        ]\n","    )"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:15:59.229219Z","iopub.status.busy":"2024-04-27T10:15:59.228842Z","iopub.status.idle":"2024-04-27T10:15:59.242277Z","shell.execute_reply":"2024-04-27T10:15:59.241504Z","shell.execute_reply.started":"2024-04-27T10:15:59.229195Z"},"trusted":true},"outputs":[],"source":["def get_val_transforms(keys=[\"image\", \"label\"], image_keys=[\"image\"]):\n","    \"\"\" Get transforms for testing on FLAIR images and ground truth:\n","    - Loads 3D images and masks from Nifti file\n","    - Adds channel dimention\n","    - Applies intensity normalisation to scans\n","    - Converts to torch.Tensor()\n","    \"\"\"\n","    return Compose(\n","        [\n","            LoadImaged(keys=keys),\n","            AddChanneld(keys=keys),\n","            NormalizeIntensityd(keys=image_keys, nonzero=True),\n","            ToTensord(keys=keys),\n","        ]\n","    )"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:15:59.243650Z","iopub.status.busy":"2024-04-27T10:15:59.243393Z","iopub.status.idle":"2024-04-27T10:15:59.258687Z","shell.execute_reply":"2024-04-27T10:15:59.257780Z","shell.execute_reply.started":"2024-04-27T10:15:59.243627Z"},"trusted":true},"outputs":[],"source":["def get_train_dataloader(flair_path, gts_path, num_workers, cache_rate=0.1):\n","    \"\"\"\n","    Get dataloader for training \n","    Args:\n","      flair_path: `str`, path to directory with FLAIR images from Train set.\n","      gts_path:  `str`, path to directory with ground truth lesion segmentation \n","                    binary masks images from Train set.\n","      num_workers:  `int`,  number of worker threads to use for parallel processing\n","                    of images\n","      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n","    Returns:\n","      monai.data.DataLoader() class object.\n","    \"\"\"\n","    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii\")),\n","                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n","    segs = sorted(glob(os.path.join(gts_path, \"*gt_isovox.nii\")),\n","                  key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding ground truths\n","\n","    files = [{\"image\": fl, \"label\": seg} for fl, seg in zip(flair, segs)]\n","\n","    print(\"Number of training files:\", len(files))\n","\n","    ds = CacheDataset(data=files, transform=get_train_transforms(),\n","                      cache_rate=cache_rate, num_workers=num_workers)\n","    return DataLoader(ds, batch_size=1, shuffle=True,\n","                      num_workers=num_workers)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:15:59.260425Z","iopub.status.busy":"2024-04-27T10:15:59.260071Z","iopub.status.idle":"2024-04-27T10:15:59.272056Z","shell.execute_reply":"2024-04-27T10:15:59.271195Z","shell.execute_reply.started":"2024-04-27T10:15:59.260398Z"},"trusted":true},"outputs":[],"source":["def get_val_dataloader(flair_path, gts_path, num_workers, cache_rate=0.1, bm_path=None):\n","    \"\"\"\n","    Get dataloader for validation and testing. Either with or without brain masks.\n","\n","    Args:\n","      flair_path: `str`, path to directory with FLAIR images.\n","      gts_path:  `str`, path to directory with ground truth lesion segmentation \n","                    binary masks images.\n","      num_workers:  `int`,  number of worker threads to use for parallel processing\n","                    of images\n","      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n","      bm_path:   `None|str`. If `str`, then defines path to directory with\n","                 brain masks. If `None`, dataloader does not return brain masks. \n","    Returns:\n","      monai.data.DataLoader() class object.\n","    \"\"\"\n","    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii\")),\n","                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n","    segs = sorted(glob(os.path.join(gts_path, \"*_isovox.nii\")),\n","                  key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding ground truths\n","\n","    if bm_path is not None:\n","        bms = sorted(glob(os.path.join(bm_path, \"*isovox_fg_mask.nii\")),\n","                     key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding brain masks\n","\n","        assert len(flair) == len(segs) == len(bms), f\"Some files must be missing: {[len(flair), len(segs), len(bms)]}\"\n","\n","        files = [\n","            {\"image\": fl, \"label\": seg, \"brain_mask\": bm} for fl, seg, bm\n","            in zip(flair, segs, bms)\n","        ]\n","\n","        val_transforms = get_val_transforms(keys=[\"image\", \"label\", \"brain_mask\"])\n","    else:\n","        assert len(flair) == len(segs), f\"Some files must be missing: {[len(flair), len(segs)]}\"\n","\n","        files = [{\"image\": fl, \"label\": seg} for fl, seg in zip(flair, segs)]\n","\n","        val_transforms = get_val_transforms()\n","\n","    print(\"Number of validation files:\", len(files))\n","\n","    ds = CacheDataset(data=files, transform=val_transforms,\n","                      cache_rate=cache_rate, num_workers=num_workers)\n","    return DataLoader(ds, batch_size=1, shuffle=False,\n","                      num_workers=num_workers)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:15:59.273596Z","iopub.status.busy":"2024-04-27T10:15:59.273270Z","iopub.status.idle":"2024-04-27T10:15:59.285684Z","shell.execute_reply":"2024-04-27T10:15:59.284890Z","shell.execute_reply.started":"2024-04-27T10:15:59.273549Z"},"trusted":true},"outputs":[],"source":["def get_flair_dataloader(flair_path, num_workers, cache_rate=0.1, bm_path=None):\n","    \"\"\"\n","    Get dataloader with FLAIR images only for inference\n","    \n","    Args:\n","      flair_path: `str`, path to directory with FLAIR images from Train set.\n","      num_workers:  `int`,  number of worker threads to use for parallel processing\n","                    of images\n","      cache_rate:  `float` in (0.0, 1.0], percentage of cached data in total.\n","      bm_path:   `None|str`. If `str`, then defines path to directory with\n","                 brain masks. If `None`, dataloader does not return brain masks.\n","    Returns:\n","      monai.data.DataLoader() class object.\n","    \"\"\"\n","    flair = sorted(glob(os.path.join(flair_path, \"*FLAIR_isovox.nii\")),\n","                   key=lambda i: int(re.sub('\\D', '', i)))  # Collect all flair images sorted\n","\n","    if bm_path is not None:\n","        bms = sorted(glob(os.path.join(bm_path, \"*isovox_fg_mask.nii\")),\n","                     key=lambda i: int(re.sub('\\D', '', i)))  # Collect all corresponding brain masks\n","\n","        assert len(flair) == len(bms), f\"Some files must be missing: {[len(flair), len(bms)]}\"\n","\n","        files = [{\"image\": fl, \"brain_mask\": bm} for fl, bm in zip(flair, bms)]\n","\n","        val_transforms = get_val_transforms(keys=[\"image\", \"brain_mask\"])\n","    else:\n","        files = [{\"image\": fl} for fl in flair]\n","\n","        val_transforms = get_val_transforms(keys=[\"image\"])\n","\n","    print(\"Number of FLAIR files:\", len(files))\n","\n","    ds = CacheDataset(data=files, transform=val_transforms,\n","                      cache_rate=cache_rate, num_workers=num_workers)\n","    return DataLoader(ds, batch_size=1, shuffle=False,\n","                      num_workers=num_workers)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:15:59.288664Z","iopub.status.busy":"2024-04-27T10:15:59.288281Z","iopub.status.idle":"2024-04-27T10:15:59.297231Z","shell.execute_reply":"2024-04-27T10:15:59.296303Z","shell.execute_reply.started":"2024-04-27T10:15:59.288636Z"},"trusted":true},"outputs":[],"source":["def remove_connected_components(segmentation, l_min=9):\n","    \"\"\"\n","    Remove all lesions with less or equal amount of voxels than `l_min` from a \n","    binary segmentation mask `segmentation`.\n","    Args:\n","      segmentation: `numpy.ndarray` of shape [H, W, D], with a binary lesions segmentation mask.\n","      l_min:  `int`, minimal amount of voxels in a lesion.\n","    Returns:\n","      Binary lesion segmentation mask (`numpy.ndarray` of shape [H, W, D])\n","      only with connected components that have more than `l_min` voxels.\n","    \"\"\"\n","    labeled_seg, num_labels = ndimage.label(segmentation)\n","    label_list = np.unique(labeled_seg)\n","    num_elements_by_lesion = ndimage.labeled_comprehension(segmentation, labeled_seg, label_list, np.sum, float, 0)\n","\n","    seg2 = np.zeros_like(segmentation)\n","    for i_el, n_el in enumerate(num_elements_by_lesion):\n","        if n_el > l_min:\n","            current_voxels = np.stack(np.where(labeled_seg == i_el), axis=1)\n","            seg2[current_voxels[:, 0],\n","                 current_voxels[:, 1],\n","                 current_voxels[:, 2]] = 1\n","    return seg2"]},{"cell_type":"markdown","metadata":{},"source":["## Training Function"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:55:23.308082Z","iopub.status.busy":"2024-04-27T10:55:23.307588Z","iopub.status.idle":"2024-04-27T10:55:23.353972Z","shell.execute_reply":"2024-04-27T10:55:23.352936Z","shell.execute_reply.started":"2024-04-27T10:55:23.308036Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Training function for UNet model with Dice and Focal loss.\n","Args:\n","    Data Args:\n","        path_train_data: `str`, path to directory with FLAIR images from Train set.\n","        path_train_gts: `str`, path to directory with ground truth lesion segmentation\n","        path_val_data: `str`, path to directory with FLAIR images from Validation set.\n","        path_val_gts: `str`, path to directory with ground truth lesion segmentation\n","    Model Args:\n","        learning_rate: `float`, learning rate for the optimizer.\n","        n_epochs: `int`, number of epochs to train the model.\n","        seed: `int`, random seed for reproducibility.\n","        threshold: `float`, probability threshold for binarization of the output.\n","        num_workers: `int`, number of worker threads to use for parallel processing\n","        path_save: `str`, path to directory where to save the best model.\n","        val_interval: `int`, interval for validation.\n","\"\"\"\n","def trainSwinUNETR(path_train_data, path_train_gts, path_val_data, path_val_gts, learning_rate = 1e-5, n_epochs = 300, seed = 42, threshold = 0.4, num_workers = 10, path_save = '', val_interval = 5):\n","    # setting up the seeds\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    \n","    # setting up the device\n","    device = get_default_device()\n","    torch.multiprocessing.set_sharing_strategy('file_system')\n","    \n","    # Initialise dataloaders\n","    train_loader = get_train_dataloader(flair_path=path_train_data, \n","                                        gts_path=path_train_gts, \n","                                        num_workers=num_workers)\n","    val_loader = get_val_dataloader(flair_path=path_val_data, \n","                                    gts_path=path_val_gts, \n","                                    num_workers=num_workers)\n","    # Initialise the model\n","    model = SwinUNETR(\n","        img_size=(96,96,96),\n","        spatial_dims=3,\n","        in_channels=1,\n","        out_channels=2).to(device)\n","    \n","    loss_function = DiceLoss(to_onehot_y=True, \n","                             softmax=True, sigmoid=False,\n","                             include_background=False)\n","    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n","    act = nn.Softmax(dim=1)\n","    \n","    epoch_num = n_epochs\n","    val_interval = val_interval\n","    thresh = threshold\n","    gamma_focal = 2.0\n","    dice_weight = 0.5\n","    focal_weight = 1.0\n","    roi_size = (96, 96, 96)\n","    sw_batch_size = 4\n","    \n","    best_metric, best_metric_epoch = -1, -1\n","    epoch_loss_values, metric_values = [], []\n","    \n","    # Training Loop\n","    for epoch in range(epoch_num):\n","        print(\"-\" * 10)\n","        print(f\"epoch {epoch + 1}/{epoch_num}\")\n","        model.train()\n","        epoch_loss = 0\n","        step = 0\n","        for batch_data in train_loader:\n","            n_samples = batch_data[\"image\"].size(0)\n","            for m in range(0,batch_data[\"image\"].size(0), 2):\n","                step += 2\n","                inputs, labels = (\n","                    batch_data[\"image\"][m:(m+2)].to(device),\n","                    batch_data[\"label\"][m:(m+2)].type(torch.LongTensor).to(device))\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                \n","                # Dice loss\n","                loss1 = loss_function(outputs, labels)\n","                # Focal loss\n","                ce_loss = nn.CrossEntropyLoss(reduction='none')\n","                ce = ce_loss(outputs, torch.squeeze(labels, dim=1))\n","                pt = torch.exp(-ce)\n","                loss2 = (1 - pt)**gamma_focal * ce \n","                loss2 = torch.mean(loss2)\n","                loss = dice_weight * loss1 + focal_weight * loss2              \n","                \n","                loss.backward()\n","                optimizer.step()\n","                \n","                epoch_loss += loss.item()\n","                if step % 100 == 0:\n","                    step_print = int(step/2)\n","                    print(f\"{step_print}/{(len(train_loader)*n_samples) // (train_loader.batch_size*2)}, train_loss: {loss.item():.4f}\")\n","\n","        epoch_loss /= step_print\n","        epoch_loss_values.append(epoch_loss)\n","        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","        \n","        # Validation\n","        if (epoch + 1) % val_interval == 0:\n","            model.eval()\n","            with torch.no_grad():\n","                metric_sum = 0.0\n","                metric_count = 0\n","                for val_data in val_loader:\n","                    val_inputs, val_labels = (\n","                        val_data[\"image\"].to(device),\n","                        val_data[\"label\"].to(device)\n","                        )\n","                    \n","                    val_outputs = sliding_window_inference(val_inputs, roi_size, \n","                                                           sw_batch_size, \n","                                                           model, mode='gaussian')\n","                   \n","                    gt = np.squeeze(val_labels.cpu().numpy())\n","                    \n","                    seg = act(val_outputs).cpu().numpy()\n","                    seg= np.squeeze(seg[0,1])\n","                    seg[seg >= thresh] = 1\n","                    seg[seg < thresh] = 0\n","                    \n","                    value = dice_metric(ground_truth=gt.flatten(), predictions=seg.flatten())\n","\n","                    metric_count += 1\n","                    metric_sum += value.sum().item()\n","                \n","                metric = metric_sum / metric_count\n","                metric_values.append(metric)\n","                if metric > best_metric:\n","                    best_metric = metric\n","                    best_metric_epoch = epoch + 1\n","                    torch.save(model.state_dict(), os.path.join(path_save, \"Best_model_finetuning_\"+str(best_metric_epoch)+\"_epoch.pth\"))\n","                    print(\"saved new best metric model\")\n","                print(f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n","                                    f\"\\nbest mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n","                                    )\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train The Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-27T10:55:50.322984Z","iopub.status.busy":"2024-04-27T10:55:50.322110Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Got CUDA!\n","Number of training files: 33\n"]},{"name":"stderr","output_type":"stream","text":["Loading dataset: 100%|██████████| 3/3 [00:00<00:00, 11.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Number of validation files: 7\n","----------\n","epoch 1/100\n","50/528, train_loss: 0.5518\n","100/528, train_loss: 0.5187\n","150/528, train_loss: 0.5412\n","200/528, train_loss: 0.5248\n","250/528, train_loss: 0.5222\n","300/528, train_loss: 0.5078\n","350/528, train_loss: 0.5175\n","400/528, train_loss: 0.4508\n","450/528, train_loss: 0.5105\n","500/528, train_loss: 0.5160\n","epoch 1 average loss: 0.5416\n","----------\n","epoch 2/100\n","50/528, train_loss: 0.5411\n","100/528, train_loss: 0.4928\n","150/528, train_loss: 0.4635\n","200/528, train_loss: 0.5033\n","250/528, train_loss: 0.4924\n","300/528, train_loss: 0.3784\n","350/528, train_loss: 0.4836\n","400/528, train_loss: 0.5108\n","450/528, train_loss: 0.4996\n","500/528, train_loss: 0.4783\n","epoch 2 average loss: 0.5075\n","----------\n","epoch 3/100\n","50/528, train_loss: 0.5033\n","100/528, train_loss: 0.5129\n","150/528, train_loss: 0.4406\n","200/528, train_loss: 0.4492\n","250/528, train_loss: 0.4204\n","300/528, train_loss: 0.3583\n","350/528, train_loss: 0.4547\n","400/528, train_loss: 0.5019\n","450/528, train_loss: 0.4594\n","500/528, train_loss: 0.3534\n","epoch 3 average loss: 0.4946\n","----------\n","epoch 4/100\n","50/528, train_loss: 0.4505\n","100/528, train_loss: 0.5083\n","150/528, train_loss: 0.5045\n","200/528, train_loss: 0.5024\n","250/528, train_loss: 0.4313\n","300/528, train_loss: 0.4800\n","350/528, train_loss: 0.4348\n","400/528, train_loss: 0.4374\n","450/528, train_loss: 0.3442\n","500/528, train_loss: 0.4261\n","epoch 4 average loss: 0.4870\n","----------\n","epoch 5/100\n","50/528, train_loss: 0.4363\n","100/528, train_loss: 0.4997\n","150/528, train_loss: 0.4987\n","200/528, train_loss: 0.4993\n","250/528, train_loss: 0.4355\n","300/528, train_loss: 0.4167\n","350/528, train_loss: 0.4956\n","400/528, train_loss: 0.3831\n","450/528, train_loss: 0.4276\n","500/528, train_loss: 0.3521\n","epoch 5 average loss: 0.4756\n","saved new best metric model\n","current epoch: 5 current mean dice: 0.5095\n","best mean dice: 0.5095 at epoch: 5\n","----------\n","epoch 6/100\n","50/528, train_loss: 0.5082\n","100/528, train_loss: 0.4362\n","150/528, train_loss: 0.4209\n","200/528, train_loss: 0.4160\n","250/528, train_loss: 0.4624\n","300/528, train_loss: 0.5025\n","350/528, train_loss: 0.4054\n","400/528, train_loss: 0.4983\n","450/528, train_loss: 0.4238\n","500/528, train_loss: 0.4786\n","epoch 6 average loss: 0.4674\n","----------\n","epoch 7/100\n","50/528, train_loss: 0.5021\n","100/528, train_loss: 0.4593\n","150/528, train_loss: 0.3827\n","200/528, train_loss: 0.4938\n","250/528, train_loss: 0.3055\n","300/528, train_loss: 0.4580\n","350/528, train_loss: 0.3568\n","400/528, train_loss: 0.2729\n","450/528, train_loss: 0.4541\n","500/528, train_loss: 0.3968\n","epoch 7 average loss: 0.4563\n","----------\n","epoch 8/100\n","50/528, train_loss: 0.2613\n","100/528, train_loss: 0.3466\n","150/528, train_loss: 0.3283\n","200/528, train_loss: 0.4905\n","250/528, train_loss: 0.4966\n","300/528, train_loss: 0.4437\n","350/528, train_loss: 0.4888\n","400/528, train_loss: 0.5002\n","450/528, train_loss: 0.3601\n","500/528, train_loss: 0.3894\n","epoch 8 average loss: 0.4455\n","----------\n","epoch 9/100\n","50/528, train_loss: 0.3873\n","100/528, train_loss: 0.3292\n","150/528, train_loss: 0.3759\n","200/528, train_loss: 0.4854\n","250/528, train_loss: 0.5016\n","300/528, train_loss: 0.3207\n","350/528, train_loss: 0.4438\n","400/528, train_loss: 0.3677\n","450/528, train_loss: 0.4946\n","500/528, train_loss: 0.5004\n","epoch 9 average loss: 0.4333\n","----------\n","epoch 10/100\n","50/528, train_loss: 0.3460\n","100/528, train_loss: 0.4643\n","150/528, train_loss: 0.4894\n","200/528, train_loss: 0.4913\n","250/528, train_loss: 0.4826\n","300/528, train_loss: 0.4837\n","350/528, train_loss: 0.3931\n","400/528, train_loss: 0.3720\n","450/528, train_loss: 0.4799\n","500/528, train_loss: 0.2541\n","epoch 10 average loss: 0.4250\n","saved new best metric model\n","current epoch: 10 current mean dice: 0.5213\n","best mean dice: 0.5213 at epoch: 10\n","----------\n","epoch 11/100\n","50/528, train_loss: 0.3701\n","100/528, train_loss: 0.4393\n","150/528, train_loss: 0.3593\n","200/528, train_loss: 0.4864\n","250/528, train_loss: 0.4984\n","300/528, train_loss: 0.2690\n","350/528, train_loss: 0.3585\n","400/528, train_loss: 0.4826\n","450/528, train_loss: 0.3585\n","500/528, train_loss: 0.4981\n","epoch 11 average loss: 0.4129\n","----------\n","epoch 12/100\n","50/528, train_loss: 0.4975\n","100/528, train_loss: 0.3398\n","150/528, train_loss: 0.2871\n","200/528, train_loss: 0.4688\n","250/528, train_loss: 0.4944\n","300/528, train_loss: 0.4361\n","350/528, train_loss: 0.4000\n","400/528, train_loss: 0.4097\n","450/528, train_loss: 0.3550\n","500/528, train_loss: 0.2336\n","epoch 12 average loss: 0.4002\n","----------\n","epoch 13/100\n","50/528, train_loss: 0.4919\n","100/528, train_loss: 0.3660\n","150/528, train_loss: 0.2787\n","200/528, train_loss: 0.3004\n","250/528, train_loss: 0.2347\n","300/528, train_loss: 0.2472\n","350/528, train_loss: 0.3469\n","400/528, train_loss: 0.4689\n","450/528, train_loss: 0.5072\n","500/528, train_loss: 0.2097\n","epoch 13 average loss: 0.3934\n","----------\n","epoch 14/100\n","50/528, train_loss: 0.2308\n","100/528, train_loss: 0.4631\n","150/528, train_loss: 0.5007\n","200/528, train_loss: 0.4830\n","250/528, train_loss: 0.3347\n","300/528, train_loss: 0.4384\n","350/528, train_loss: 0.4480\n","400/528, train_loss: 0.4850\n","450/528, train_loss: 0.4868\n","500/528, train_loss: 0.2478\n","epoch 14 average loss: 0.3827\n","----------\n","epoch 15/100\n","50/528, train_loss: 0.3463\n","100/528, train_loss: 0.4311\n","150/528, train_loss: 0.2427\n","200/528, train_loss: 0.1467\n","250/528, train_loss: 0.4788\n","300/528, train_loss: 0.2915\n","350/528, train_loss: 0.2968\n","400/528, train_loss: 0.4001\n","450/528, train_loss: 0.3470\n","500/528, train_loss: 0.3548\n","epoch 15 average loss: 0.3732\n","saved new best metric model\n","current epoch: 15 current mean dice: 0.5601\n","best mean dice: 0.5601 at epoch: 15\n","----------\n","epoch 16/100\n","50/528, train_loss: 0.2702\n","100/528, train_loss: 0.2004\n","150/528, train_loss: 0.4691\n","200/528, train_loss: 0.4519\n","250/528, train_loss: 0.2094\n","300/528, train_loss: 0.4714\n","350/528, train_loss: 0.3009\n","400/528, train_loss: 0.3439\n","450/528, train_loss: 0.2497\n","500/528, train_loss: 0.4812\n","epoch 16 average loss: 0.3634\n","----------\n","epoch 17/100\n","50/528, train_loss: 0.3270\n","100/528, train_loss: 0.2842\n","150/528, train_loss: 0.4227\n","200/528, train_loss: 0.1692\n","250/528, train_loss: 0.3134\n","300/528, train_loss: 0.1724\n","350/528, train_loss: 0.2021\n","400/528, train_loss: 0.4338\n","450/528, train_loss: 0.2841\n","500/528, train_loss: 0.2792\n","epoch 17 average loss: 0.3532\n","----------\n","epoch 18/100\n","50/528, train_loss: 0.2247\n","100/528, train_loss: 0.4652\n","150/528, train_loss: 0.4871\n","200/528, train_loss: 0.2485\n","250/528, train_loss: 0.1707\n","300/528, train_loss: 0.2716\n","350/528, train_loss: 0.2467\n","400/528, train_loss: 0.4241\n","450/528, train_loss: 0.4546\n","500/528, train_loss: 0.4585\n","epoch 18 average loss: 0.3433\n","----------\n","epoch 19/100\n","50/528, train_loss: 0.2897\n","100/528, train_loss: 0.2392\n","150/528, train_loss: 0.4799\n","200/528, train_loss: 0.3973\n","250/528, train_loss: 0.1605\n","300/528, train_loss: 0.1880\n","350/528, train_loss: 0.2748\n","400/528, train_loss: 0.4148\n","450/528, train_loss: 0.4982\n","500/528, train_loss: 0.4722\n","epoch 19 average loss: 0.3316\n","----------\n","epoch 20/100\n","50/528, train_loss: 0.3088\n","100/528, train_loss: 0.4354\n","150/528, train_loss: 0.4511\n","200/528, train_loss: 0.4712\n","250/528, train_loss: 0.1835\n","300/528, train_loss: 0.4541\n","350/528, train_loss: 0.3070\n","400/528, train_loss: 0.2197\n","450/528, train_loss: 0.1735\n","500/528, train_loss: 0.3365\n","epoch 20 average loss: 0.3252\n","current epoch: 20 current mean dice: 0.5474\n","best mean dice: 0.5601 at epoch: 15\n","----------\n","epoch 21/100\n","50/528, train_loss: 0.3002\n","100/528, train_loss: 0.2939\n","150/528, train_loss: 0.1656\n","200/528, train_loss: 0.1200\n","250/528, train_loss: 0.2552\n","300/528, train_loss: 0.4283\n","350/528, train_loss: 0.1675\n","400/528, train_loss: 0.4245\n","450/528, train_loss: 0.3985\n","500/528, train_loss: 0.2493\n","epoch 21 average loss: 0.3185\n","----------\n","epoch 22/100\n","50/528, train_loss: 0.2227\n","100/528, train_loss: 0.1618\n","150/528, train_loss: 0.2839\n","200/528, train_loss: 0.2146\n","250/528, train_loss: 0.2730\n","300/528, train_loss: 0.1990\n","350/528, train_loss: 0.1713\n","400/528, train_loss: 0.4747\n","450/528, train_loss: 0.1817\n","500/528, train_loss: 0.4788\n","epoch 22 average loss: 0.3064\n","----------\n","epoch 23/100\n","50/528, train_loss: 0.2397\n","100/528, train_loss: 0.2157\n","150/528, train_loss: 0.4322\n","200/528, train_loss: 0.1432\n","250/528, train_loss: 0.2193\n","300/528, train_loss: 0.3200\n","350/528, train_loss: 0.3821\n","400/528, train_loss: 0.2241\n","450/528, train_loss: 0.2148\n","500/528, train_loss: 0.2728\n","epoch 23 average loss: 0.3010\n","----------\n","epoch 24/100\n","50/528, train_loss: 0.2171\n","100/528, train_loss: 0.1915\n","150/528, train_loss: 0.1573\n","200/528, train_loss: 0.3801\n","250/528, train_loss: 0.4785\n","300/528, train_loss: 0.3869\n","350/528, train_loss: 0.2328\n","400/528, train_loss: 0.3900\n","450/528, train_loss: 0.4487\n","500/528, train_loss: 0.3437\n","epoch 24 average loss: 0.2895\n","----------\n","epoch 25/100\n","50/528, train_loss: 0.3376\n","100/528, train_loss: 0.1305\n","150/528, train_loss: 0.2353\n","200/528, train_loss: 0.2034\n","250/528, train_loss: 0.2085\n","300/528, train_loss: 0.1436\n","350/528, train_loss: 0.3796\n","400/528, train_loss: 0.1524\n","450/528, train_loss: 0.2362\n","500/528, train_loss: 0.4749\n","epoch 25 average loss: 0.2821\n","saved new best metric model\n","current epoch: 25 current mean dice: 0.6420\n","best mean dice: 0.6420 at epoch: 25\n","----------\n","epoch 26/100\n","50/528, train_loss: 0.1785\n","100/528, train_loss: 0.4349\n","150/528, train_loss: 0.4790\n","200/528, train_loss: 0.1970\n","250/528, train_loss: 0.1055\n","300/528, train_loss: 0.3265\n","350/528, train_loss: 0.2128\n","400/528, train_loss: 0.1644\n","450/528, train_loss: 0.3491\n","500/528, train_loss: 0.1828\n","epoch 26 average loss: 0.2742\n","----------\n","epoch 27/100\n","50/528, train_loss: 0.2008\n","100/528, train_loss: 0.2006\n","150/528, train_loss: 0.3092\n","200/528, train_loss: 0.1410\n","250/528, train_loss: 0.1788\n","300/528, train_loss: 0.2051\n","350/528, train_loss: 0.3188\n","400/528, train_loss: 0.3132\n","450/528, train_loss: 0.3792\n","500/528, train_loss: 0.3147\n","epoch 27 average loss: 0.2690\n","----------\n","epoch 28/100\n","50/528, train_loss: 0.3009\n","100/528, train_loss: 0.1893\n","150/528, train_loss: 0.3869\n","200/528, train_loss: 0.1358\n","250/528, train_loss: 0.1854\n","300/528, train_loss: 0.2614\n","350/528, train_loss: 0.3200\n","400/528, train_loss: 0.1607\n","450/528, train_loss: 0.2842\n","500/528, train_loss: 0.3886\n","epoch 28 average loss: 0.2666\n","----------\n","epoch 29/100\n","50/528, train_loss: 0.3277\n","100/528, train_loss: 0.1667\n","150/528, train_loss: 0.1547\n","200/528, train_loss: 0.4006\n","250/528, train_loss: 0.1393\n","300/528, train_loss: 0.1715\n","350/528, train_loss: 0.3308\n","400/528, train_loss: 0.1878\n","450/528, train_loss: 0.3853\n","500/528, train_loss: 0.2794\n","epoch 29 average loss: 0.2587\n","----------\n","epoch 30/100\n","50/528, train_loss: 0.1497\n","100/528, train_loss: 0.1608\n","150/528, train_loss: 0.3355\n","200/528, train_loss: 0.1643\n","250/528, train_loss: 0.3305\n","300/528, train_loss: 0.3117\n","350/528, train_loss: 0.3114\n","400/528, train_loss: 0.2246\n","450/528, train_loss: 0.3206\n","500/528, train_loss: 0.1683\n","epoch 30 average loss: 0.2536\n","saved new best metric model\n","current epoch: 30 current mean dice: 0.6811\n","best mean dice: 0.6811 at epoch: 30\n","----------\n","epoch 31/100\n","50/528, train_loss: 0.1743\n","100/528, train_loss: 0.0973\n","150/528, train_loss: 0.2004\n","200/528, train_loss: 0.1585\n","250/528, train_loss: 0.2313\n","300/528, train_loss: 0.3184\n","350/528, train_loss: 0.1502\n","400/528, train_loss: 0.1374\n","450/528, train_loss: 0.3382\n","500/528, train_loss: 0.2800\n","epoch 31 average loss: 0.2461\n","----------\n","epoch 32/100\n","50/528, train_loss: 0.1645\n","100/528, train_loss: 0.1845\n","150/528, train_loss: 0.3124\n","200/528, train_loss: 0.3083\n","250/528, train_loss: 0.2797\n","300/528, train_loss: 0.1229\n","350/528, train_loss: 0.3467\n","400/528, train_loss: 0.1471\n","450/528, train_loss: 0.1720\n","500/528, train_loss: 0.1871\n","epoch 32 average loss: 0.2448\n","----------\n","epoch 33/100\n","50/528, train_loss: 0.1764\n","100/528, train_loss: 0.1694\n","150/528, train_loss: 0.5008\n","200/528, train_loss: 0.1654\n","250/528, train_loss: 0.3178\n","300/528, train_loss: 0.1442\n"]}],"source":["train_data = '/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Train/FLAIR'\n","train_gts = '/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Train/GroundTruth'\n","val_data = '/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Val/FLAIR'\n","val_data_gts = '/kaggle/input/sdcombinedextracted/ShiftsDatasetCombinedExtracted/Val/GroundTruth'\n","\n","trainSwinUNETR(train_data, train_gts, val_data, val_data_gts, learning_rate = 1e-5, n_epochs = 100, seed = 42, threshold = 0.4, num_workers = 4, path_save = '/kaggle/working/', val_interval = 5)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4826829,"sourceId":8166514,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
